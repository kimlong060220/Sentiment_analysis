{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edb0203a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import Embedding,Dense,Dropout,Bidirectional,LSTM,GRU,Input,GlobalAveragePooling1D,LayerNormalization\n",
    "from tensorflow.keras.optimizers import Adam,SGD\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from pyvi import ViTokenizer\n",
    "from pyvi import ViUtils\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf4928b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D,MaxPooling1D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03163ab2",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de7ada58",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_sw = pd.read_csv(\"./data/data_have_sw.csv\")\n",
    "data_df_no_sw = pd.read_csv(\"./data/data_no_sw.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22b47e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df_sw_copy = data_df_sw.copy()\n",
    "data_df_no_sw_copy = data_df_no_sw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f46f3f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 29776/29776 [00:00<00:00, 66393.91it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 29771/29771 [00:00<00:00, 82307.34it/s]\n"
     ]
    }
   ],
   "source": [
    "data_df_sw_copy[\"token\"] = data_df_sw_copy.progress_apply(lambda x: x['token'].split(\" \"), axis = 1)\n",
    "data_df_no_sw_copy[\"token\"] = data_df_no_sw_copy.progress_apply(lambda x: str(x['token']).split(\" \"), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d136f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9eaf6d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "ftmodel_hs_sw = FastText(sentences= data_df_sw_copy[\"token\"] ,vector_size=300  ,window =15 , min_count=5)\n",
    "ftmodel_no_sw = FastText(sentences= data_df_no_sw_copy[\"token\"] ,vector_size=300  ,window =15 , min_count=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f5184f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fastText_train(word,ftmodel):\n",
    "    try:\n",
    "        embedding=ftmodel[word]\n",
    "    except:\n",
    "        embedding=np.zeros((300,))\n",
    "    return embedding \n",
    "def get_embedding(word):\n",
    "    try:\n",
    "        embedding=fasttex_model[word]\n",
    "    except:\n",
    "        embedding=np.zeros((300,))\n",
    "    return embedding \n",
    "\n",
    "def word_tokenize_(data_frame, col1, col2):\n",
    "    data_frame[col2] = data_frame[col1].apply(lambda x: list(set(word_tokenize(str(x)))) )\n",
    "    return data_frame \n",
    "\n",
    "def convert_to_array(data_frame, col):\n",
    "    return np.array(data_frame[col].tolist()).reshape(-1,1)\n",
    "\n",
    "def create_vector_train(list_token_):\n",
    "    return [np.mean(np.array(list(map(get_embedding,tok_sent[0]))), axis = 0) for tok_sent in list_token_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9244a1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "fasttex_model = fasttext.load_model('./fasttext/cc.vi.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15e29320",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Long\\anaconda3\\envs\\do_an\\lib\\site-packages\\ipykernel_launcher.py:19: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n"
     ]
    }
   ],
   "source": [
    "data_train_has_sw = convert_to_array(data_df_sw_copy,\"token\")\n",
    "data_train_no_sw = convert_to_array(data_df_no_sw_copy,\"token\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7f2a8694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 29776/29776 [00:00<00:00, 1751410.72it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_has_sw = []\n",
    "for ele in tqdm(range(len(data_train_has_sw))):\n",
    "    X_train_has_sw.append(data_train_has_sw[ele])\n",
    "\n",
    "X_train_has_sw = create_vector_train(X_train_has_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6983f2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 29771/29771 [00:00<00:00, 1240486.63it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_no_sw = []\n",
    "for ele in tqdm(range(len(data_train_no_sw))):\n",
    "    X_train_no_sw.append(data_train_no_sw[ele])\n",
    "\n",
    "X_train_no_sw = create_vector_train(X_train_no_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "06f5ff06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29776\n",
      "29771\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train_has_sw))\n",
    "print(len(X_train_no_sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b7cb9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('./data/data_vector_fastext_has_sw.npy ', X_train_has_sw, allow_pickle=True)\n",
    "np.save('./data/data_vector_fastext_no_sw.npy ', X_train_no_sw, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906f190a",
   "metadata": {},
   "source": [
    "# ML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74625b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "data_df_sw_copy['label'] = le.fit_transform(data_df_sw_copy['label'].astype(str))\n",
    "data_df_no_sw_copy['label'] = le.fit_transform(data_df_no_sw_copy['label'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a99313e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_has_sw = np.load('D:\\do_an\\data\\data_vector_fastext_has_sw.npy .npy')\n",
    "X_train_no_sw = np.load('D:\\do_an\\data\\data_vector_fastext_no_sw.npy .npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fed3e2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3774354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1, x_test_1, y_train_1, y_test_1 = train_test_split(X_train_has_sw, data_df_sw_copy['label'], test_size=0.2, shuffle=True, random_state=42) \n",
    "x_train_2, x_test_2, y_train_2, y_test_2 = train_test_split(X_train_no_sw, data_df_no_sw_copy['label'], test_size=0.2, shuffle=True, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb2e426c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26f5f8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8456    0.7841    0.8137      2339\n",
      "           1     0.8666    0.9074    0.8865      3617\n",
      "\n",
      "    accuracy                         0.8590      5956\n",
      "   macro avg     0.8561    0.8457    0.8501      5956\n",
      "weighted avg     0.8584    0.8590    0.8579      5956\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8426    0.7214    0.7773      2337\n",
      "           1     0.8354    0.9129    0.8724      3618\n",
      "\n",
      "    accuracy                         0.8378      5955\n",
      "   macro avg     0.8390    0.8172    0.8249      5955\n",
      "weighted avg     0.8382    0.8378    0.8351      5955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr_model_1 = LogisticRegression(multi_class='ovr', solver='sag')\n",
    "lr_model_1.fit(x_train_1, y_train_1)\n",
    "y_predict_1 = lr_model_1.predict(x_test_1)\n",
    "\n",
    "print(classification_report(y_test_1, y_predict_1, labels= [0,1], digits=4))\n",
    "\n",
    "\n",
    "lr_model_2 = LogisticRegression(multi_class='ovr', solver='sag')\n",
    "lr_model_2.fit(x_train_2, y_train_2)\n",
    "y_predict_2 = lr_model_2.predict(x_test_2)\n",
    "\n",
    "print(classification_report(y_test_2, y_predict_2, labels= [0,1], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a7f7d484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8656    0.8260    0.8453      2339\n",
      "           1     0.8907    0.9171    0.9037      3617\n",
      "\n",
      "    accuracy                         0.8813      5956\n",
      "   macro avg     0.8782    0.8715    0.8745      5956\n",
      "weighted avg     0.8808    0.8813    0.8808      5956\n",
      "\n",
      "[LibSVM]              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8630    0.7869    0.8232      2337\n",
      "           1     0.8698    0.9193    0.8938      3618\n",
      "\n",
      "    accuracy                         0.8673      5955\n",
      "   macro avg     0.8664    0.8531    0.8585      5955\n",
      "weighted avg     0.8671    0.8673    0.8661      5955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model_1 = SVC(decision_function_shape = 'ovo', verbose=10 )\n",
    "svc_model_1.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_predict_1 = svc_model_1.predict(x_test_1)\n",
    "\n",
    "print(classification_report(y_test_1, y_predict_1, labels= [0,1], digits=4))\n",
    "\n",
    "\n",
    "\n",
    "svc_model_2 = SVC(decision_function_shape = 'ovo', verbose=10 )\n",
    "svc_model_2.fit(x_train_2, y_train_2)\n",
    "\n",
    "y_predict_2 = svc_model_2.predict(x_test_2)\n",
    "\n",
    "print(classification_report(y_test_2, y_predict_2, labels= [0,1], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0660e9c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6383    0.6541    0.6461      2339\n",
      "           1     0.7727    0.7603    0.7664      3617\n",
      "\n",
      "    accuracy                         0.7186      5956\n",
      "   macro avg     0.7055    0.7072    0.7063      5956\n",
      "weighted avg     0.7199    0.7186    0.7192      5956\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6305    0.6346    0.6325      2337\n",
      "           1     0.7630    0.7598    0.7614      3618\n",
      "\n",
      "    accuracy                         0.7107      5955\n",
      "   macro avg     0.6968    0.6972    0.6970      5955\n",
      "weighted avg     0.7110    0.7107    0.7108      5955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "clf_1 = tree.DecisionTreeClassifier()\n",
    "clf_1.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_predict_1 = clf_1.predict(x_test_1)\n",
    "\n",
    "print(classification_report(y_test_1, y_predict_1, labels= [0,1], digits=4))\n",
    "\n",
    "\n",
    "\n",
    "clf_2 = tree.DecisionTreeClassifier()\n",
    "\n",
    "clf_2.fit(x_train_2, y_train_2)\n",
    "\n",
    "y_predict_2 = clf_2.predict(x_test_2)\n",
    "\n",
    "print(classification_report(y_test_2, y_predict_2, labels= [0,1], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7b95e84e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6353    0.3814    0.4766      2339\n",
      "           1     0.6821    0.8584    0.7602      3617\n",
      "\n",
      "    accuracy                         0.6711      5956\n",
      "   macro avg     0.6587    0.6199    0.6184      5956\n",
      "weighted avg     0.6637    0.6711    0.6488      5956\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6331    0.4142    0.5008      2337\n",
      "           1     0.6907    0.8449    0.7601      3618\n",
      "\n",
      "    accuracy                         0.6759      5955\n",
      "   macro avg     0.6619    0.6296    0.6304      5955\n",
      "weighted avg     0.6681    0.6759    0.6583      5955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb_1 = GaussianNB()\n",
    "gnb_1.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_predict_1 = gnb_1.predict(x_test_1)\n",
    "\n",
    "print(classification_report(y_test_1, y_predict_1, labels= [0,1], digits=4))\n",
    "\n",
    "\n",
    "\n",
    "gnb_2 = GaussianNB()\n",
    "\n",
    "gnb_2.fit(x_train_2, y_train_2)\n",
    "\n",
    "y_predict_2 = gnb_2.predict(x_test_2)\n",
    "\n",
    "print(classification_report(y_test_2, y_predict_2, labels= [0,1], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d6cf6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8143    0.7631    0.7879      2339\n",
      "           1     0.8528    0.8875    0.8698      3617\n",
      "\n",
      "    accuracy                         0.8387      5956\n",
      "   macro avg     0.8336    0.8253    0.8289      5956\n",
      "weighted avg     0.8377    0.8387    0.8376      5956\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8112    0.7206    0.7632      2337\n",
      "           1     0.8317    0.8917    0.8606      3618\n",
      "\n",
      "    accuracy                         0.8245      5955\n",
      "   macro avg     0.8214    0.8061    0.8119      5955\n",
      "weighted avg     0.8236    0.8245    0.8224      5955\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_1 = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "rfc_1.fit(x_train_1, y_train_1)\n",
    "\n",
    "y_predict_1 = rfc_1.predict(x_test_1)\n",
    "\n",
    "print(classification_report(y_test_1, y_predict_1, labels= [0,1], digits=4))\n",
    "\n",
    "\n",
    "\n",
    "rfc_2 = RandomForestClassifier(max_depth=None, random_state=0)\n",
    "\n",
    "rfc_2.fit(x_train_2, y_train_2)\n",
    "\n",
    "y_predict_2 = rfc_2.predict(x_test_2)\n",
    "\n",
    "print(classification_report(y_test_2, y_predict_2, labels= [0,1], digits=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9198227e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
